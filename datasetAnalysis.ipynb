{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d5619ae32d75d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94411d9584dc732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(\"data/fhvhv_tripdata_2023-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98097a94b55a7bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d578298c2413d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b89785b7039b0b",
   "metadata": {},
   "source": [
    "# Data Cleanup / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea8bfed4e6cfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Null Values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7870d237ac75932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused columns\n",
    "df.drop(['dispatching_base_num','originating_base_num','base_passenger_fare','tolls','bcf','sales_tax','congestion_surcharge','airport_fee','tips','driver_pay','access_a_ride_flag','wav_match_flag','wav_request_flag'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737ca68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting only uber rides\n",
    "df = df[df['hvfhs_license_num'] == 'HV0003']\n",
    "df.drop(['hvfhs_license_num'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b1baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['PULocationID'].isin([264, 265]) & ~df['DOLocationID'].isin([264, 265])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c515a35",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the 99th percentile value for trip_miles\n",
    "trip_miles_99th_percentile = df['trip_miles'].quantile(0.99)\n",
    "df = df[df['trip_miles'] < trip_miles_99th_percentile]\n",
    "\n",
    "# Calculate the 99th percentile value for trip_time\n",
    "trip_time_99th_percentile = df['trip_time'].quantile(0.99)\n",
    "df = df[df['trip_time'] < trip_time_99th_percentile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bf265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cyclic features for time of the day and day of the week\n",
    "df['hour'] = df['request_datetime'].dt.hour\n",
    "df['weekday'] = df['request_datetime'].dt.dayofweek\n",
    "\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
    "df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)\n",
    "df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data to get the demand for each PULocationID\n",
    "demand = df.groupby(['PULocationID', 'DOLocationID', 'hour', 'weekday']).size().reset_index(name='demand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45eae90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the cyclic features back to the demand dataframe\n",
    "demand = demand.merge(df[['PULocationID', 'DOLocationID', 'hour', 'weekday', 'hour_sin', 'hour_cos', 'weekday_sin', 'weekday_cos']].drop_duplicates(), on=['PULocationID', 'DOLocationID', 'hour', 'weekday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba0f45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d8731f",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c66f57d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the 1st percentile value for demand\n",
    "demand_1st_percentile = demand['demand'].quantile(0.005)\n",
    "demand = demand[demand['demand'] > demand_1st_percentile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e316d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the bins and labels\n",
    "bins = [0, 1, 2, 3, 4, 5, float('inf')]\n",
    "labels = [-1 ,0, 1, 2, 3, 4]\n",
    "\n",
    "# Create a new column 'demand_category' with the binned values\n",
    "demand['demand_category'] = pd.cut(demand['demand'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd58007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'demand_category' column to integer type\n",
    "demand['demand_category'] = demand['demand_category'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337f46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand['demand_category'].replace({2: 1, 3: 1, 4: 2}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6a51e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "demand.to_csv('data/demand.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29875481c046e76",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaec2cf9ceee97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "df['PULocationID'].value_counts(sort=False).sort_index().plot(kind='bar')\n",
    "plt.xlabel(\"Start Area\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc765e33ba8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "df['request_datetime'].dt.hour.value_counts(sort=False).sort_index().plot(kind='bar')\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d3b5ab5d3ea8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,6))\n",
    "df['request_datetime'].dt.dayofweek.value_counts(sort=False).sort_index().plot(kind='bar')\n",
    "#df['request_datetime'].dt.day_name().value_counts(sort=False).plot(kind='bar')\n",
    "plt.xlabel(\"Day of week\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1aae2b55666bf0",
   "metadata": {},
   "source": [
    "# Predicting Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea9ce32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "correlation_matrix = demand.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdd7c913f4ee3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = demand[['hour_sin', 'hour_cos', 'weekday_sin', 'weekday_cos', 'PULocationID']]\n",
    "y = demand['demand_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c27b1411455269",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b1784092b3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435c44be166de92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unloading the dataframe to save memory\n",
    "df = []\n",
    "demand = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0abbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da7dc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(len(np.unique(y_train)), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aa4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Calculate class weights\n",
    "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
    "class_weights_dict[2] *= 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27b34c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e8995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"y_train unique values:\", set(y_train))\n",
    "print(\"class_weights_dict keys:\", class_weights_dict.keys())\n",
    "print(\"y_train types:\", set(type(label) for label in y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d982fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "history = model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test), class_weight=class_weights_dict)\n",
    "model.save('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deccee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting graphs for accuracy \n",
    "plt.plot(history.history['accuracy'], label='training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db84d0",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae07eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9261ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test Loss', score[0])\n",
    "print('Test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f866d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb861679",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adab8bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "import seaborn as sns\n",
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2615d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def predict_demand(date_time):\n",
    "    # Extract features from the date_time\n",
    "    hour = (date_time.hour + (date_time.minute //15 * 15 / 60))\n",
    "    #hour = date_time.hour\n",
    "    weekday = date_time.weekday()\n",
    "    \n",
    "    hour_sin = np.sin(2 * np.pi * hour / 24)\n",
    "    hour_cos = np.cos(2 * np.pi * hour / 24)\n",
    "    weekday_sin = np.sin(2 * np.pi * weekday / 7)\n",
    "    weekday_cos = np.cos(2 * np.pi * weekday / 7)\n",
    "    \n",
    "    # Create a dataframe with all possible PULocationID values\n",
    "    PULocationIDs = X['PULocationID'].unique()\n",
    "    data = pd.DataFrame({\n",
    "        'hour_sin': [hour_sin] * len(PULocationIDs),\n",
    "        'hour_cos': [hour_cos] * len(PULocationIDs),\n",
    "        'weekday_sin': [weekday_sin] * len(PULocationIDs),\n",
    "        'weekday_cos': [weekday_cos] * len(PULocationIDs),\n",
    "        'PULocationID': PULocationIDs\n",
    "    })\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(data)\n",
    "    predicted_categories = np.argmax(predictions, axis=1)\n",
    "    data['predicted_category'] = predicted_categories\n",
    "    \n",
    "    return data[['PULocationID', 'predicted_category']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc45237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "date_time = datetime.datetime.now()\n",
    "demand_per_area = predict_demand(date_time)\n",
    "print(demand_per_area)\n",
    "demand_per_area.to_csv('data/output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f44dfbe9081f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_zones = pd.read_csv('data/taxi_zones.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237e2edee1c86d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from shapely import wkt\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from folium import GeoJson\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Merge taxi zones data with demand output data on LocationID\n",
    "merged_df = pd.merge(taxi_zones, demand_per_area, left_on=\"LocationID\", right_on=\"PULocationID\")\n",
    "\n",
    "# Define color mapping for demand levels\n",
    "demand_colors = {0: 'red', 1: 'orange', 2: 'green'}\n",
    "\n",
    "# Initialize the map centered around NYC\n",
    "nyc_map = folium.Map(location=[40.7128, -74.0060], zoom_start=10)\n",
    "\n",
    "# Parse and plot each zone\n",
    "for _, row in merged_df.iterrows():\n",
    "    # Parse the geometry from WKT and set demand level color\n",
    "    demand_level = row['predicted_category']\n",
    "    color = demand_colors[demand_level]\n",
    "\n",
    "    # Parse the MULTIPOLYGON from the_geom column\n",
    "    geometry = wkt.loads(row['the_geom'])\n",
    "    if isinstance(geometry, (MultiPolygon, Polygon)):\n",
    "        geo_json = GeoJson(data=geometry.__geo_interface__, \n",
    "                           style_function=lambda x, color=color: {\n",
    "                               'fillColor': color, 'color': 'black', 'weight': 1, 'fillOpacity': 0.5\n",
    "                           })\n",
    "        geo_json.add_to(nyc_map)\n",
    "\n",
    "# Display map\n",
    "nyc_map\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
